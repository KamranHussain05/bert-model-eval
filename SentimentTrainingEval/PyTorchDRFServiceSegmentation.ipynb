{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "PyTorchDRFServiceSegmentation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# BERT Service Classification with FastText Embeddings"
   ],
   "metadata": {
    "id": "ELtvT3oNCWW3"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Use the Transformers library for direct interfacing with Huggingface for the full model. This allows access to all 1.8 million parameters for hypertuning and more model control. \n",
    "\n",
    "Reference: https://towardsdatascience.com/text-classification-with-bert-in-pytorch-887965e5820f"
   ],
   "metadata": {
    "id": "xpxRkdQUhIXd"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "! pip install transformers"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WnaZusBdhAl6",
    "outputId": "e70029d7-4429-4dcb-fdd7-294809161ef6"
   },
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\n",
      "\u001B[K     |████████████████████████████████| 4.0 MB 11.2 MB/s \n",
      "\u001B[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
      "Collecting huggingface-hub<1.0,>=0.1.0\n",
      "  Downloading huggingface_hub-0.5.1-py3-none-any.whl (77 kB)\n",
      "\u001B[K     |████████████████████████████████| 77 kB 3.7 MB/s \n",
      "\u001B[?25hCollecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
      "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
      "\u001B[K     |████████████████████████████████| 6.6 MB 43.1 MB/s \n",
      "\u001B[?25hCollecting sacremoses\n",
      "  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n",
      "\u001B[K     |████████████████████████████████| 895 kB 38.4 MB/s \n",
      "\u001B[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
      "Collecting pyyaml>=5.1\n",
      "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
      "\u001B[K     |████████████████████████████████| 596 kB 36.8 MB/s \n",
      "\u001B[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.8)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
      "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
      "  Attempting uninstall: pyyaml\n",
      "    Found existing installation: PyYAML 3.13\n",
      "    Uninstalling PyYAML-3.13:\n",
      "      Successfully uninstalled PyYAML-3.13\n",
      "Successfully installed huggingface-hub-0.5.1 pyyaml-6.0 sacremoses-0.0.49 tokenizers-0.12.1 transformers-4.18.0\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Import relevant modules and libraries"
   ],
   "metadata": {
    "id": "IX-YIaeShj0e"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "y1gRBEEeB_47"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "\n",
    "from transformers import BertModel, BertTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Loading"
   ],
   "metadata": {
    "id": "GRwwSfedix7h"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Look for the proper datafile and load it if its in the proper format"
   ],
   "metadata": {
    "id": "9CuYa3ydi89h"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "path = 'daily_weather_training_data_normalized.csv'\n",
    "\n",
    "if(os.path.exists(path)):\n",
    "  print('File Found:', path)\n",
    "  df = pd.read_csv(path, usecols=['text', 'label'], low_memory=True, dtype=str, encoding='utf-8')\n",
    "  df.head()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wn796R_Ci2F7",
    "outputId": "3442f805-9e01-4529-9520-ddba09a143b9"
   },
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Found: daily_weather_training_data_normalized.csv\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Preprocess the data and ensure the dataset is balanced"
   ],
   "metadata": {
    "id": "64QGcFImj5kV"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "df['label'] = df['label'].astype(int)\n",
    "df['text'] = df['text'].astype(str)\n",
    "\n",
    "df['label'].value_counts()\n",
    "df.groupby(['label']).size().plot.bar()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 294
    },
    "id": "s7Z4YQMlj5DC",
    "outputId": "d380f55b-8967-41c0-abbd-17f4297945e8"
   },
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "<AxesSubplot:xlabel='label'>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEDCAYAAADZUdTgAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAQrUlEQVR4nO3ca4xd1XnG8f8TDEmbVNiEqUVtEyPFTQqtAsTi0lRRElQwJKqpRBBpVCxkyR/q3KRKDfSLVQgRfGhpqBpUK7g1KQ1BtBFWiqCWk7RKKy4mEG4O9ZRAbQvwJDakFOVi8vbDLCenzgxzBo/PAOv/k0Zn7Xetvc/aOvKzt/fZ+6SqkCT14Q3zPQFJ0ugY+pLUEUNfkjpi6EtSRwx9SeqIoS9JHVkw3xN4Occff3wtX758vqchSa8p999///eqamyqvld16C9fvpzt27fP9zQk6TUlyVPT9Xl5R5I6YuhLUkeGCv0kC5PcluQ7SXYkOTvJcUm2JtnZXhe1sUlyfZLxJA8lOX1gO2va+J1J1hypnZIkTW3YM/3PAXdW1TuBdwE7gMuBbVW1AtjWlgHOB1a0v3XADQBJjgM2AGcCZwAbDh4oJEmjMWPoJzkWeC9wI0BV/biqngNWA5vbsM3Aha29GripJt0NLExyAnAesLWq9lXVfmArsGoO90WSNINhzvRPAiaAv03yQJIvJHkzsLiqnm5jngEWt/YSYNfA+rtbbbq6JGlEhgn9BcDpwA1VdRrwv/z8Ug4ANfn7zHPyG81J1iXZnmT7xMTEXGxSktQME/q7gd1VdU9bvo3Jg8Cz7bIN7XVv698DLBtYf2mrTVf/f6pqY1WtrKqVY2NTPlsgSXqFZnw4q6qeSbIryTuq6nHgHOCx9rcGuKa93t5W2QJ8LMktTH5p+3xVPZ3kLuCzA1/engtcMbe7c3iWX/7P8z2FI+rJaz4431M4ovz8Xrv87EZn2CdyPw7cnOQY4AngMib/l3BrkrXAU8DFbewdwAXAOPBiG0tV7UtyFXBfG3dlVe2bk72QJA1lqNCvqgeBlVN0nTPF2ALWT7OdTcCmWcxPkjSHfCJXkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSR4YK/SRPJnk4yYNJtrfacUm2JtnZXhe1epJcn2Q8yUNJTh/Yzpo2fmeSNUdmlyRJ05nNmf77q+rUqlrZli8HtlXVCmBbWwY4H1jR/tYBN8DkQQLYAJwJnAFsOHigkCSNxuFc3lkNbG7tzcCFA/WbatLdwMIkJwDnAVural9V7Qe2AqsO4/0lSbM0bOgX8C9J7k+yrtUWV9XTrf0MsLi1lwC7Btbd3WrT1SVJI7JgyHG/U1V7kvwqsDXJdwY7q6qS1FxMqB1U1gGceOKJc7FJSVIz1Jl+Ve1pr3uBrzB5Tf7ZdtmG9rq3Dd8DLBtYfWmrTVc/9L02VtXKqlo5NjY2u72RJL2sGUM/yZuT/MrBNnAu8AiwBTh4B84a4PbW3gJc2u7iOQt4vl0Gugs4N8mi9gXuua0mSRqRYS7vLAa+kuTg+H+oqjuT3AfcmmQt8BRwcRt/B3ABMA68CFwGUFX7klwF3NfGXVlV++ZsTyRJM5ox9KvqCeBdU9S/D5wzRb2A9dNsaxOwafbTlCTNBZ/IlaSOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1JGhQz/JUUkeSPLVtnxSknuSjCf5cpJjWv2NbXm89S8f2MYVrf54kvPmfG8kSS9rNmf6nwR2DCxfC1xXVW8H9gNrW30tsL/Vr2vjSHIycAlwCrAK+HySow5v+pKk2Rgq9JMsBT4IfKEtB/gAcFsbshm4sLVXt2Va/zlt/Grglqr6UVV9FxgHzpiDfZAkDWnYM/2/BP4E+GlbfivwXFUdaMu7gSWtvQTYBdD6n2/jf1afYh1J0gjMGPpJPgTsrar7RzAfkqxLsj3J9omJiVG8pSR1Y5gz/fcAv5fkSeAWJi/rfA5YmGRBG7MU2NPae4BlAK3/WOD7g/Up1vmZqtpYVSurauXY2Nisd0iSNL0ZQ7+qrqiqpVW1nMkvYr9WVR8Fvg5c1IatAW5v7S1tmdb/taqqVr+k3d1zErACuHfO9kSSNKMFMw+Z1qeBW5J8BngAuLHVbwS+mGQc2MfkgYKqejTJrcBjwAFgfVW9dBjvL0mapVmFflV9A/hGaz/BFHffVNUPgQ9Ps/7VwNWznaQkaW74RK4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOzBj6Sd6U5N4k307yaJI/a/WTktyTZDzJl5Mc0+pvbMvjrX/5wLauaPXHk5x3xPZKkjSlYc70fwR8oKreBZwKrEpyFnAtcF1VvR3YD6xt49cC+1v9ujaOJCcDlwCnAKuAzyc5ag73RZI0gxlDvya90BaPbn8FfAC4rdU3Axe29uq2TOs/J0la/Zaq+lFVfRcYB86Yi52QJA1nqGv6SY5K8iCwF9gK/BfwXFUdaEN2A0taewmwC6D1Pw+8dbA+xTqSpBEYKvSr6qWqOhVYyuTZ+TuP1ISSrEuyPcn2iYmJI/U2ktSlWd29U1XPAV8HzgYWJlnQupYCe1p7D7AMoPUfC3x/sD7FOoPvsbGqVlbVyrGxsdlMT5I0g2Hu3hlLsrC1fwn4XWAHk+F/URu2Bri9tbe0ZVr/16qqWv2SdnfPScAK4N452g9J0hAWzDyEE4DN7U6bNwC3VtVXkzwG3JLkM8ADwI1t/I3AF5OMA/uYvGOHqno0ya3AY8ABYH1VvTS3uyNJejkzhn5VPQScNkX9Caa4+6aqfgh8eJptXQ1cPftpSpLmgk/kSlJHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6siMoZ9kWZKvJ3ksyaNJPtnqxyXZmmRne13U6klyfZLxJA8lOX1gW2va+J1J1hy53ZIkTWWYM/0DwB9X1cnAWcD6JCcDlwPbqmoFsK0tA5wPrGh/64AbYPIgAWwAzgTOADYcPFBIkkZjxtCvqqer6lut/T/ADmAJsBrY3IZtBi5s7dXATTXpbmBhkhOA84CtVbWvqvYDW4FVc7kzkqSXN6tr+kmWA6cB9wCLq+rp1vUMsLi1lwC7Blbb3WrT1Q99j3VJtifZPjExMZvpSZJmMHToJ3kL8I/Ap6rqB4N9VVVAzcWEqmpjVa2sqpVjY2NzsUlJUjNU6Cc5msnAv7mq/qmVn22XbWive1t9D7BsYPWlrTZdXZI0IsPcvRPgRmBHVf3FQNcW4OAdOGuA2wfql7a7eM4Cnm+Xge4Czk2yqH2Be26rSZJGZMEQY94D/CHwcJIHW+1PgWuAW5OsBZ4CLm59dwAXAOPAi8BlAFW1L8lVwH1t3JVVtW8udkKSNJwZQ7+qvglkmu5zphhfwPpptrUJ2DSbCUqS5o5P5EpSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SerIjKGfZFOSvUkeGagdl2Rrkp3tdVGrJ8n1ScaTPJTk9IF11rTxO5OsOTK7I0l6OcOc6f8dsOqQ2uXAtqpaAWxrywDnAyva3zrgBpg8SAAbgDOBM4ANBw8UkqTRmTH0q+rfgH2HlFcDm1t7M3DhQP2mmnQ3sDDJCcB5wNaq2ldV+4Gt/OKBRJJ0hL3Sa/qLq+rp1n4GWNzaS4BdA+N2t9p09V+QZF2S7Um2T0xMvMLpSZKmcthf5FZVATUHczm4vY1VtbKqVo6Njc3VZiVJvPLQf7ZdtqG97m31PcCygXFLW226uiRphF5p6G8BDt6Bswa4faB+abuL5yzg+XYZ6C7g3CSL2he457aaJGmEFsw0IMmXgPcBxyfZzeRdONcAtyZZCzwFXNyG3wFcAIwDLwKXAVTVviRXAfe1cVdW1aFfDkuSjrAZQ7+qPjJN1zlTjC1g/TTb2QRsmtXsJElzyidyJakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdWTkoZ9kVZLHk4wnuXzU7y9JPRtp6Cc5Cvhr4HzgZOAjSU4e5RwkqWejPtM/Axivqieq6sfALcDqEc9Bkrq1YMTvtwTYNbC8GzhzcECSdcC6tvhCksdHNLf5cDzwvVG9Wa4d1Tt1w8/vtev1/tm9bbqOUYf+jKpqI7BxvucxCkm2V9XK+Z6HXhk/v9eunj+7UV/e2QMsG1he2mqSpBEYdejfB6xIclKSY4BLgC0jnoMkdWukl3eq6kCSjwF3AUcBm6rq0VHO4VWmi8tYr2N+fq9d3X52qar5noMkaUR8IleSOmLoS1JHDH1J6sir7j7917Mk72TyCeQlrbQH2FJVO+ZvVtLrX/u3twS4p6peGKivqqo7529mo+eZ/ogk+TSTPzsR4N72F+BL/vDca1uSy+Z7Dppekk8AtwMfBx5JMvjTL5+dn1nNH+/eGZEk/wmcUlU/OaR+DPBoVa2Yn5npcCX576o6cb7noakleRg4u6peSLIcuA34YlV9LskDVXXa/M5wtLy8Mzo/BX4NeOqQ+gmtT69iSR6argtYPMq5aNbecPCSTlU9meR9wG1J3sbk59cVQ390PgVsS7KTn//o3InA24GPzdekNLTFwHnA/kPqAf5j9NPRLDyb5NSqehCgnfF/CNgE/Na8zmweGPojUlV3Jvl1Jn9eevCL3Puq6qX5m5mG9FXgLQeDY1CSb4x8NpqNS4EDg4WqOgBcmuRv5mdK88dr+pLUEe/ekaSOGPqS1BFDXxqQ5IUZ+pcneWSW2/y7JBcd3sykuWHoS1JHDH1pCknekmRbkm8lefiQpzgXJLk5yY4ktyX55bbOu5P8a5L7k9yV5IR5mr40LUNfmtoPgd+vqtOB9wN/nuTggzzvAD5fVb8B/AD4oyRHA38FXFRV72byHvCr52He0svyPn1pagE+m+S9TD4xvYSfP3m7q6r+vbX/HvgEcCfwm8DWdmw4Cnh6pDOWhmDoS1P7KDAGvLuqfpLkSeBNre/Qh1uKyYPEo1V19uimKM2el3ekqR0L7G2B/37gbQN9JyY5GO5/AHwTeBwYO1hPcnSSU0Y6Y2kIhr40tZuBle0XGi8FvjPQ9ziwPskOYBFwQ1X9GLgIuDbJt4EHgd8e7ZSlmfkzDJLUEc/0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR35PzVWZSEXdNjtAAAAAElFTkSuQmCC\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Tokenization and Tensorfication"
   ],
   "metadata": {
    "id": "3oTxyyMumIYx"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load the pretrained BERT base cased tokenizer from huggingface, through pytorch. The labels are also setup here, labels include dictionaries for both the main weather dataset and the"
   ],
   "metadata": {
    "id": "EWq5J0DAuv_r"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "labels = {\n",
    "    0:0,\n",
    "    1:1,\n",
    "    2:2,\n",
    "}\n",
    "\n",
    "# labels = {\n",
    "#     'positive' : 0,\n",
    "#     'negative' : 1,\n",
    "#     'neutral' : 2\n",
    "# }\n",
    "\n",
    "# labels = {\n",
    "#     'flight-planning' : 0,\n",
    "#     'ground-operations' : 1,\n",
    "#     'weather' : 2,\n",
    "#     'emergency' : 3,\n",
    "#     'communication' : 4\n",
    "\n",
    "# }"
   ],
   "metadata": {
    "id": "ANSAWqQymN9i"
   },
   "execution_count": 42,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Connection error, and we cannot find the requested files in the cached path. Please try again or make sure your Internet connection is on.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-42-52a3475fa617>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mtokenizer\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mBertTokenizer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfrom_pretrained\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"bert-base-cased\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m labels = {\n\u001B[1;32m      4\u001B[0m     \u001B[0;36m0\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m     \u001B[0;36m1\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Documents/GitHub/bert-model-eval/venv/lib/python3.6/site-packages/transformers/tokenization_utils_base.py\u001B[0m in \u001B[0;36mfrom_pretrained\u001B[0;34m(cls, pretrained_model_name_or_path, *init_inputs, **kwargs)\u001B[0m\n\u001B[1;32m   1730\u001B[0m                         \u001B[0mlocal_files_only\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mlocal_files_only\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1731\u001B[0m                         \u001B[0muse_auth_token\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0muse_auth_token\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1732\u001B[0;31m                         \u001B[0muser_agent\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0muser_agent\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1733\u001B[0m                     )\n\u001B[1;32m   1734\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Documents/GitHub/bert-model-eval/venv/lib/python3.6/site-packages/transformers/file_utils.py\u001B[0m in \u001B[0;36mcached_path\u001B[0;34m(url_or_filename, cache_dir, force_download, proxies, resume_download, user_agent, extract_compressed_file, force_extract, use_auth_token, local_files_only)\u001B[0m\n\u001B[1;32m   1927\u001B[0m             \u001B[0muser_agent\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0muser_agent\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1928\u001B[0m             \u001B[0muse_auth_token\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0muse_auth_token\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1929\u001B[0;31m             \u001B[0mlocal_files_only\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mlocal_files_only\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1930\u001B[0m         )\n\u001B[1;32m   1931\u001B[0m     \u001B[0;32melif\u001B[0m \u001B[0mos\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexists\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0murl_or_filename\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Documents/GitHub/bert-model-eval/venv/lib/python3.6/site-packages/transformers/file_utils.py\u001B[0m in \u001B[0;36mget_from_cache\u001B[0;34m(url, cache_dir, force_download, proxies, etag_timeout, resume_download, user_agent, use_auth_token, local_files_only)\u001B[0m\n\u001B[1;32m   2176\u001B[0m                 \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2177\u001B[0m                     raise ValueError(\n\u001B[0;32m-> 2178\u001B[0;31m                         \u001B[0;34m\"Connection error, and we cannot find the requested files in the cached path.\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   2179\u001B[0m                         \u001B[0;34m\" Please try again or make sure your Internet connection is on.\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2180\u001B[0m                     )\n",
      "\u001B[0;31mValueError\u001B[0m: Connection error, and we cannot find the requested files in the cached path. Please try again or make sure your Internet connection is on."
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create the numpy dataset"
   ],
   "metadata": {
    "id": "7XwgbSdqu8oC"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.labels = [labels[label] for label in df['label']]\n",
    "        self.texts = [tokenizer(text, \n",
    "                               padding='max_length', max_length = 512, truncation=True,\n",
    "                                return_tensors=\"pt\") for text in df['text']]\n",
    "\n",
    "    def classes(self):\n",
    "        return self.labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def get_batch_labels(self, idx):\n",
    "        # Fetch a batch of labels\n",
    "        return np.array(self.labels[idx])\n",
    "\n",
    "    def get_batch_texts(self, idx):\n",
    "        # Fetch a batch of inputs\n",
    "        return self.texts[idx]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        batch_texts = self.get_batch_texts(idx)\n",
    "        batch_y = self.get_batch_labels(idx)\n",
    "\n",
    "        return batch_texts, batch_y"
   ],
   "metadata": {
    "id": "7VCphzEauyp6"
   },
   "execution_count": 38,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Set the training and evaluation dataframes and convert the numpy features"
   ],
   "metadata": {
    "id": "6ZSClsVOvgAh"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "np.random.seed(112)\n",
    "df_train, df_val, df_test = np.split(df.sample(frac=1, random_state=42), \n",
    "                                     [int(.8*len(df)), int(.9*len(df))])\n",
    "\n",
    "print(len(df_train),len(df_val), len(df_test))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XypGK5GZve_t",
    "outputId": "9a4ed797-4225-4a60-e027-782edd7d5891"
   },
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14212 1777 1777\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model Building"
   ],
   "metadata": {
    "id": "04HkJ7ypvC25"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class BertClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, dropout=0.5):\n",
    "\n",
    "        super(BertClassifier, self).__init__()\n",
    "\n",
    "        self.bert = BertModel.from_pretrained('bert-base-cased')\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear = nn.Linear(768, 5)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, input_id, mask):\n",
    "\n",
    "        _, pooled_output = self.bert(input_ids= input_id, attention_mask=mask,return_dict=False)\n",
    "        dropout_output = self.dropout(pooled_output)\n",
    "        linear_output = self.linear(dropout_output)\n",
    "        final_layer = self.relu(linear_output)\n",
    "\n",
    "        return final_layer"
   ],
   "metadata": {
    "id": "2PJY0Mbnvtlh"
   },
   "execution_count": 22,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training"
   ],
   "metadata": {
    "id": "6hNSceipwK8n"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Set up the training loops"
   ],
   "metadata": {
    "id": "jmb1HFx2wMk6"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def train(model, train_data, val_data, learning_rate, epochs):\n",
    "\n",
    "    train, val = Dataset(train_data), Dataset(val_data)\n",
    "\n",
    "    train_dataloader = torch.utils.data.DataLoader(train, batch_size=2, shuffle=True)\n",
    "    val_dataloader = torch.utils.data.DataLoader(val, batch_size=2)\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = Adam(model.parameters(), lr= learning_rate)\n",
    "\n",
    "    if use_cuda:\n",
    "\n",
    "            model = model.cuda()\n",
    "            criterion = criterion.cuda()\n",
    "\n",
    "    for epoch_num in range(epochs):\n",
    "\n",
    "            total_acc_train = 0\n",
    "            total_loss_train = 0\n",
    "\n",
    "            for train_input, train_label in tqdm(train_dataloader):\n",
    "\n",
    "                train_label = train_label.to(device)\n",
    "                mask = train_input['attention_mask'].to(device)\n",
    "                input_id = train_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "                output = model(input_id, mask)\n",
    "                \n",
    "                batch_loss = criterion(output, train_label)\n",
    "                total_loss_train += batch_loss.item()\n",
    "                \n",
    "                acc = (output.argmax(dim=1) == train_label).sum().item()\n",
    "                total_acc_train += acc\n",
    "\n",
    "                model.zero_grad()\n",
    "                batch_loss.backward()\n",
    "                optimizer.step()\n",
    "            \n",
    "            total_acc_val = 0\n",
    "            total_loss_val = 0\n",
    "\n",
    "            with torch.no_grad():\n",
    "\n",
    "                for val_input, val_label in val_dataloader:\n",
    "\n",
    "                    val_label = val_label.to(device)\n",
    "                    mask = val_input['attention_mask'].to(device)\n",
    "                    input_id = val_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "                    output = model(input_id, mask)\n",
    "\n",
    "                    batch_loss = criterion(output, val_label)\n",
    "                    total_loss_val += batch_loss.item()\n",
    "                    \n",
    "                    acc = (output.argmax(dim=1) == val_label).sum().item()\n",
    "                    total_acc_val += acc\n",
    "            \n",
    "            print(\n",
    "                f'Epochs: {epoch_num + 1} | Train Loss: {total_loss_train / len(train_data): .3f} \\\n",
    "                | Train Accuracy: {total_acc_train / len(train_data): .3f} \\\n",
    "                | Val Loss: {total_loss_val / len(val_data): .3f} \\\n",
    "                | Val Accuracy: {total_acc_val / len(val_data): .3f}')"
   ],
   "metadata": {
    "id": "y60efQtxwMVK"
   },
   "execution_count": 15,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Train the model"
   ],
   "metadata": {
    "id": "14-AfKEMwZMg"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "EPOCHS = 1\n",
    "model = BertClassifier()\n",
    "LR = 3e+6\n",
    "              \n",
    "train(model, df_train, df_val, LR, EPOCHS)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WP61ojcdwa4F",
    "outputId": "d0c582f5-2860-4f2d-f398-44d55299659f"
   },
   "execution_count": 20,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|██████████| 7106/7106 [49:34<00:00,  2.39it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epochs: 1 | Train Loss:  0.059                 | Train Accuracy:  0.957                 | Val Loss:  0.044                 | Val Accuracy:  0.967\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluate the Model"
   ],
   "metadata": {
    "id": "meKpLOSHweQB"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def evaluate(model, test_data):\n",
    "\n",
    "    test = Dataset(test_data)\n",
    "\n",
    "    test_dataloader = torch.utils.data.DataLoader(test, batch_size=5)\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    if use_cuda:\n",
    "\n",
    "        model = model.cuda()\n",
    "\n",
    "    total_acc_test = 0\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for test_input, test_label in test_dataloader:\n",
    "\n",
    "              test_label = test_label.to(device)\n",
    "              mask = test_input['attention_mask'].to(device)\n",
    "              input_id = test_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "              output = model(input_id, mask)\n",
    "              print(output.argmax(dim=1))\n",
    "\n",
    "              acc = (output.argmax(dim=1) == test_label).sum().item()\n",
    "              total_acc_test += acc\n",
    "    \n",
    "    print(f'Test Accuracy: {total_acc_test / len(test_data)*100: .3f}%')\n",
    "    \n",
    "#evaluate(model, df_test)"
   ],
   "metadata": {
    "id": "rYisZdFawdxu"
   },
   "execution_count": 43,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Save the model to a pickle file"
   ],
   "metadata": {
    "id": "F6t_C9mMDjDs"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "torch.save(model, \"model.pkl\")"
   ],
   "metadata": {
    "id": "djNz6OErBUI7"
   },
   "execution_count": 22,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model Demo"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Predictions from the model"
   ],
   "metadata": {
    "id": "3p2pT8X4Dl8s"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def predict(model, sentence):\n",
    "    test = Dataset(sentence)\n",
    "\n",
    "    output_labels = {\n",
    "        0 : 'positive',\n",
    "        1 : 'negative',\n",
    "        2 : 'neutral'\n",
    "    }\n",
    "\n",
    "    test_dataloader = torch.utils.data.DataLoader(test, batch_size=5)\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    if use_cuda:\n",
    "        model = model.gpu()\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for test_input, test_label in test_dataloader:\n",
    "\n",
    "              mask = test_input['attention_mask'].to(device)\n",
    "              input_id = test_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "              output = model(input_id, mask)\n",
    "              print(output.argmax(dim=1))\n",
    "\n",
    "              res = (output.argmax(dim=1))\n",
    "\n",
    "    return output_labels.get(res)"
   ],
   "metadata": {
    "id": "V3S9m_d7Dpwy"
   },
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "print(df_test[0:1])\n",
    "bertclassifiermodel = torch.load(\"/Users/kamranhussain/Documents/GitHub/bert-model-eval/outputs/fullBERT-epoch-1/model.pkl\", map_location=torch.device('cpu'))\n",
    "predict(bertclassifiermodel, df_test[0:1])"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YhoNlIJDDIjV",
    "outputId": "a5de83fb-4fd3-4fe4-eecb-15d64ba493e9",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 4,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-4-dc5a10d4bbf0>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdf_test\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      3\u001B[0m \u001B[0mbertclassifiermodel\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"/Users/kamranhussain/Documents/GitHub/bert-model-eval/outputs/fullBERT-epoch-1/model.pkl\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmap_location\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'cpu'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0mpredict\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbertclassifiermodel\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdf_test\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'df_test' is not defined"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ]
}