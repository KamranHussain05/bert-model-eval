{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "x2wF0bMrdpJO"
      },
      "source": [
        "# BERT Weather Condition Custom Training and Sentiment Analysis Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "jjPtK9A-dpJW"
      },
      "source": [
        "Import the necessary libraries and packages. Pandas for the dataframe and in-memory data management. Numpy for linear algebra, wordcloud and matplotlib for visualization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IElTOk96dpJW"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from wordcloud import WordCloud\n",
        "import os\n",
        "import time\n",
        "import logging"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "1XwrwvBydpJY"
      },
      "source": [
        "Import and read the data into a pandas dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xR5XvE75dpJZ"
      },
      "outputs": [],
      "source": [
        "path = \"daily_weather_2020.csv\" # path to data csv\n",
        "if(os.path.exists(path)):\n",
        "    print(\"File Found\")\n",
        "    df = pd.read_csv(path, usecols=['summary', 'icon'], low_memory=True, dtype=str, encoding=\"utf-8\")\n",
        "else:\n",
        "    print(\"no file found\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "mY_8Ys9pdpJZ"
      },
      "source": [
        "# Data Cleaning and Validation setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "Q1lfXMu0dpJa"
      },
      "source": [
        "Replace the icon column of the dataframe and check all the data was loaded properly as expected. The icon column items are replaced with the proper sentiment instead of the current icon value. This will help with validation when training the data. The entire dataset has validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pA2yWj7QdpJb"
      },
      "outputs": [],
      "source": [
        "# Print the dataframe basic information\n",
        "df = df.rename(columns={'summary':'statement', 'icon': 'sentiment'})\n",
        "df.info()\n",
        "# Set up the validation column in the dataframe without modifying the raw data\n",
        "def setValidation():\n",
        "    print(\"SETTING UP DATA VALIDATION\")\n",
        "    for i in range(len(df.sentiment)):\n",
        "        val = df.sentiment[i]\n",
        "        if val == 'rain' or val == 'snow' or val == 'wind' or val == 'fog':\n",
        "            df.sentiment[i] = 'negative' # negative sentiment\n",
        "        elif val == 'clear-day':\n",
        "            df.sentiment[i] = 'positive' # positive sentiment\n",
        "        elif val == 'partly-cloudy-day' or val == 'cloudy':\n",
        "            df.sentiment[i] = 'neutral' # neutral (possibly not enough data)\n",
        "    print(\"VALIDATION HAS BEEN SET UP\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "v02At_McdpJd"
      },
      "source": [
        "The validation that is setup can be tested by running the snippet below. This is a time consuming and resource intensive step, so it is not recommended to run this when reusing the same dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dDUnKrtedpJd"
      },
      "outputs": [],
      "source": [
        "# check the validation edit worked\n",
        "def checkValidationSetting():\n",
        "    print(\"CHECKING VALIDATION DATA\")\n",
        "    favorable_count = 0\n",
        "    unfavorable_count = 0\n",
        "    neutral_count = 0\n",
        "\n",
        "    for i in range(len(df.sentiment)):\n",
        "        if(df.sentiment[i] == 'positive'):\n",
        "            favorable_count +=1\n",
        "        elif(df.sentiment[i] == 'negative'):\n",
        "            unfavorable_count +=1\n",
        "        elif(df.sentiment[i] == 'neutral'):\n",
        "            neutral_count +=1\n",
        "\n",
        "    print('Favorable Count: ' + str(favorable_count))\n",
        "    print('Unfavorable Count: ' + str(unfavorable_count))\n",
        "    print('Neutral Count: ' + str(neutral_count))\n",
        "\n",
        "\n",
        "start = time.time()\n",
        "setValidation()\n",
        "checkValidationSetting()\n",
        "print('==PROCESS COMPLETED==\\n', time.time()-start, 'seconds')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Visualization\n",
        "The input data is visualized here to validate the efficacy of the dataset and the expected parameters. Wordcloud visualization was thought to not be an efficient visualization because specific words do not matter, we are testing for overall sentiment using a variety of key words, some will not appear in real world data. "
      ],
      "metadata": {
        "id": "kH4KZhl1mwmW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()\n",
        "df.info()\n",
        "\n",
        "sns.countplot(df.sentiment)\n",
        "\n",
        "df['sentiment'].value_counts()"
      ],
      "metadata": {
        "id": "A-Gmj7pzm4d_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Custom Tokenization\n",
        "Custom tokenization is needed to add weight to named entities and numerical values. Because named entities and numerical values are inherently more data rich, they should have greater weight in the word vector of the input phrase, thus custom tokenization is required. Input phrases are tokenized based on number of named entities, numerical values, length, and any sentimental key phrases."
      ],
      "metadata": {
        "id": "pXUHdrTlup22"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Necessary tokenization modules are imported first and setup"
      ],
      "metadata": {
        "id": "CgbdeH3iwYNH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "3OlRl4BBwXFq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "8lSFEygBdpJe"
      },
      "source": [
        "# Test and Train DataFrames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w9ltOKG7dpJe"
      },
      "outputs": [],
      "source": [
        "train,eval = train_test_split(df,test_size=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "91BtNd8ydpJf"
      },
      "source": [
        "# SimpleTransformers Model Setup and Build"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "E3Hhhfa5dpJf"
      },
      "source": [
        "The BERT model is setup here with the sentiment classifiers. The model segments into three classes by default. These three classes are mapped to condition sentiments in the dataframe for training validation. BERT Base-cased is the pretrain used to recognize and tokenize with weight on character casing, essential in understanding more of the data. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9o3p-D9TdpJg"
      },
      "outputs": [],
      "source": [
        "!pip install simpletransformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "myYzSRCndpJg"
      },
      "outputs": [],
      "source": [
        "from simpletransformers.classification import ClassificationModel, ClassificationArgs\n",
        "import torch\n",
        "\n",
        "# Logging for model\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "transformers_logger = logging.getLogger(\"transformers\")\n",
        "transformers_logger.setLevel(logging.WARNING)\n",
        "\n",
        "train_gpu = torch.cuda.is_available()\n",
        "\n",
        "# Create a TransformerModel\n",
        "model_args = ClassificationArgs(num_train_epochs=2,\n",
        "                                reprocess_input_data=True,\n",
        "                                overwrite_output_dir=True,\n",
        "                                train_batch_size=1)\n",
        "model = ClassificationModel('bert', 'bert-base-cased', num_labels=3, args=model_args, use_cuda=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "ht7BfbvRdpJg"
      },
      "source": [
        "The default model outputs are overwritten here and replaced with the relevant condition sentiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FxQpb1gfdpJg"
      },
      "outputs": [],
      "source": [
        "# 0,1,2 : positive,negative,neutral\n",
        "def making_label(st):\n",
        "    if(st=='positive'):\n",
        "        return 0\n",
        "    elif(st=='neutral'):\n",
        "        return 2\n",
        "    else:\n",
        "        return 1\n",
        "\n",
        "train['label'] = train['sentiment'].apply(making_label)\n",
        "eval['label'] = eval['sentiment'].apply(making_label)\n",
        "print(train.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "ppSyMA2WdpJh"
      },
      "source": [
        "The dataset is prepared for training via the creation of a test DataFrame and Evaluation DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fIhaFbRqdpJh"
      },
      "outputs": [],
      "source": [
        "train_df = pd.DataFrame({\n",
        "    'text': train['statement'][:27619],\n",
        "    'label': train['label'][:27619]\n",
        "})\n",
        "train_df.columns = [\"text\", \"labels\"]\n",
        "\n",
        "print(train_df)\n",
        "\n",
        "eval_df = pd.DataFrame({\n",
        "    'text': eval['statement'][-3069:],\n",
        "    'label': eval['label'][-3069:]\n",
        "})\n",
        "eval_df.columns=[\"text\", \"labels\"]\n",
        "print(eval_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "EOgqQNEVdpJh"
      },
      "source": [
        "The DataFrames are then run through testing and new result variables are created for evaluating model metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4xWaVCxPdpJh"
      },
      "outputs": [],
      "source": [
        "puystart = time.time()\n",
        "model.train_model(train_df, eval_df=eval_df)\n",
        "print('TRAINING TIME:', time.time()-start)\n",
        "result, model_outputs, wrong_predictions = model.eval_model(eval_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transformers Model Build and Setup\n"
      ],
      "metadata": {
        "id": "t3oC61fguJ9p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install the transformers package containing BERT and its necessary sublibraries. It also builds wheels for runtime and loads the models into runtime with the given models and tokenizers. "
      ],
      "metadata": {
        "id": "umPhYpQMuTNV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install transformers"
      ],
      "metadata": {
        "id": "OaJ2TpM4uPN_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
        "from transformers import InputExample, InputFeatures\n",
        "\n",
        "model = TFBertForSequenceClassification.from_pretrained(\"bert-base-uncased\")\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "o5EhMKk8uecH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Formatting and Refactoring"
      ],
      "metadata": {
        "id": "WDLrGgv8mJSQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Replace sentiments with numerical class representations for tensors."
      ],
      "metadata": {
        "id": "_Q3iZ5eGgrLF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()\n",
        "df.info()\n",
        "\n",
        "# Set up the validation column in the dataframe without modifying the raw data\n",
        "def setValidation():\n",
        "    print(\"REFACTORING SENTIMENTS\")\n",
        "    for i in range(len(df.sentiment)):\n",
        "        val = df.sentiment[i]\n",
        "        if val == 'negative':\n",
        "            df.sentiment[i] = 1 # negative sentiment\n",
        "        elif val == 'positive':\n",
        "            df.sentiment[i] = 0 # positive sentiment\n",
        "        elif val == 'neutral':\n",
        "            df.sentiment[i] = 2 # neutral (possibly not enough data)\n",
        "    print(\"SENTIMENTS REFACTORED\")"
      ],
      "metadata": {
        "id": "PH9TumN_gqVl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualize the modified data and determine if the refactoring was applied correctly."
      ],
      "metadata": {
        "id": "Qcevm4tGjN6H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(df.sentiment)"
      ],
      "metadata": {
        "id": "R-rLgtFYjNnA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define an example for the model, prevents discrepencies in data pulling."
      ],
      "metadata": {
        "id": "Sbm3aCISlC2g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "InputExample(guid=None,\n",
        "             text_a = \"Hello, world\",\n",
        "             text_b = None,\n",
        "             label = 1)"
      ],
      "metadata": {
        "id": "2tNBwgWuk-Jl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Begin data tensorfication and loading classes"
      ],
      "metadata": {
        "id": "ceTZ_G-TmBDu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ajLbVN_6mEuu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "csfoGI7odpJi"
      },
      "source": [
        "# Model Metrics and Model Performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "yZ73nlBZdpJi"
      },
      "source": [
        "SciKit is used to validate the model and test how the model performs when trained with this dataset. Anything above 90% is enough for the model to be considered useful and accurate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RcRV2dNydpJi"
      },
      "outputs": [],
      "source": [
        "print(result)\n",
        "print(model_outputs)\n",
        "\n",
        "lst = []\n",
        "for arr in model_outputs:\n",
        "    lst.append(np.argmax(arr))\n",
        "\n",
        "true = eval_df['labels'].tolist()\n",
        "predicted = lst"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EH_Gx7RJdpJi"
      },
      "outputs": [],
      "source": [
        "import sklearn\n",
        "mat = sklearn.metrics.confusion_matrix(true , predicted)\n",
        "print(mat)\n",
        "\n",
        "df_cm = pd.DataFrame(mat, range(3), range(3))\n",
        "\n",
        "sns.heatmap(df_cm, annot=True)\n",
        "plt.show()\n",
        "print('Model Accuracy: ', 100*sklearn.metrics.accuracy_score(true,predicted), '%')\n",
        "\n",
        "sklearn.metrics.classification_report(true,predicted,target_names=['positive','neutral','negative'])\n",
        "print('Model Accuracy: ', 100*sklearn.metrics.accuracy_score(true,predicted), '%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "esxYZ3-2dpJi"
      },
      "source": [
        "# Live Demo and Model Testing\n",
        "This function allows for the model to be evaluated with manually prompted data, a user interface for evaluating the model with real time and human generated queries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PHO1oV9ldpJi"
      },
      "outputs": [],
      "source": [
        "def get_result(statement):\n",
        "    result = model.predict([statement])\n",
        "    pos = np.where(result[1][0] == np.amax(result[1][0]))\n",
        "    pos = int(pos[0])\n",
        "    sentiment_dict = {0:'positive',1:'negative',2:'neutral'}\n",
        "    print(sentiment_dict[pos])\n",
        "    return\n",
        "\n",
        "sentiment = get_result(input(\"Input a phrase for Validation: \"))\n",
        "print(\"The input data was classified as:\", sentiment)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "BertDRFConditionSegmentation.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}