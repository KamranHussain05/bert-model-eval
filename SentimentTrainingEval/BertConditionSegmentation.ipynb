{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# BERT Weather Condition Custom Training and Sentiment Analysis Evaluation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Import the necessary libraries and packages. Pandas for the dataframe and in memory data management. Numpy for linear algebra, wordcloud and matplotlib for visualization."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from wordcloud import WordCloud\n",
    "import os"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Import and read the data into a pandas dataframe"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "path = \"daily_weather_2020.csv\" # path to data csv\n",
    "if(os.path.exists(path)):\n",
    "    print(\"File Found\")\n",
    "    df = pd.read_csv(path, usecols=['summary', 'icon'], low_memory=True, dtype=str)\n",
    "else:\n",
    "    print(\"no file found\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data cleaning and Validation setup"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Replace the icon column of the dataframe and check all the data was loaded properly as expected. The icon column items are replaced with the proper sentiment instead of the current icon value. This will help with validation when training the data. The entire dataset has validation."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Print the dataframe basic information\n",
    "df.info()\n",
    "df.rename(columns={'summary':'statement', 'icon': 'sentiment'})\n",
    "# Set up the validation column in the dataframe without modifying the raw data\n",
    "def setValidation():\n",
    "    print(\"SETTING UP DATA VALIDATION\")\n",
    "    for i in range(len(df.icon)):\n",
    "        val = df.icon[i]\n",
    "        if val == 'rain' or val == 'snow' or val == 'wind' or val == 'fog':\n",
    "            df.icon[i] = 'unfavorable' # negative sentiment\n",
    "        elif val == 'clear-day':\n",
    "            df.icon[i] = 'favorable' # positive sentiment\n",
    "        elif val == 'partly-cloudy-day' or val == 'cloudy':\n",
    "            df.icon[i] = 'neutral' # neutral (possibly not enough data)\n",
    "    print(\"VALIDATION HAS BEEN SET UP\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The validation that is setup can be tested by running the snippet below. This is a time consuming and resource intensive step, so it is not recommended to run this when reusing the same dataset."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# check the validation edit worked\n",
    "def checkValidationSetting():\n",
    "    print(\"CHECKING VALIDATION DATA\")\n",
    "    favorable_count = 0\n",
    "    unfavorable_count = 0\n",
    "    neutral_count = 0\n",
    "\n",
    "    for i in range(len(df.icon)):\n",
    "        if(df.icon[i] == 'favorable'):\n",
    "            favorable_count +=1\n",
    "        elif(df.icon[i] == 'unfavorable'):\n",
    "            unfavorable_count +=1\n",
    "        elif(df.icon[i] == 'neutral'):\n",
    "            neutral_count +=1\n",
    "\n",
    "    print('Favorable Count: ' + str(favorable_count))\n",
    "    print('Unfavorable Count: ' + str(unfavorable_count))\n",
    "    print('Neutral Count: ' + str(neutral_count))\n",
    "\n",
    "\n",
    "setValidation()\n",
    "checkValidationSetting()\n",
    "print('PROCESS COMPLETED')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Test and Train DataFrames"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train,eva = train_test_split(df,test_size=0.2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model Setup"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The BERT model is setup here with the sentiment classifiers. The model segments into three classes by default. These three classes are mapped to condition sentiments in the model setup."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip install simpletransformers"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from simpletransformers.classification import ClassificationModel\n",
    "\n",
    "# Create a TransformerModel\n",
    "model = ClassificationModel('bert', 'bert-base-cased', num_labels=3, args={'reprocess_input_data': True, 'overwrite_output_dir': True},use_cuda=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The default model outputs are overwritten here and replaced with the relevant condition sentiment"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 0,1,2 : positive,negative\n",
    "def making_label(st):\n",
    "    if(st=='favorable'):\n",
    "        return 0\n",
    "    elif(st=='unfavorable'):\n",
    "        return 1\n",
    "    else\n",
    "        return 2\n",
    "\n",
    "train['label'] = train['sentiment'].apply(making_label)\n",
    "eva['label'] = eva['sentiment'].apply(making_label)\n",
    "print(train.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The dataset is prepared for training via the creation of a test DataFrame and Evaluation DataFrame"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame({\n",
    "    'text': train['statement'][:1500].replace(r'\\n', ' ', regex=True),\n",
    "    'label': train['label'][:1500]\n",
    "})\n",
    "\n",
    "eval_df = pd.DataFrame({\n",
    "    'text': eva['statement'][-400:].replace(r'\\n', ' ', regex=True),\n",
    "    'label': eva['label'][-400:]\n",
    "})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The DataFrames are then run through testing and new result variables are created for evaluating model metrics"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.train_model(train_df)\n",
    "result, model_outputs, wrong_predictions = model.eval_model(eval_df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model Metrics and Model Performance"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "SciKit is used to validate the model and test how the model performs when trained with this dataset. Anything above 90% is enough for the model to be considered useful and accurate."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(result)\n",
    "print(model_outputs)\n",
    "\n",
    "lst = []\n",
    "for arr in model_outputs:\n",
    "    lst.append(np.argmax(arr))\n",
    "\n",
    "true = eval_df['label'].tolist()\n",
    "predicted = lst"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import sklearn\n",
    "mat = sklearn.metrics.confusion_matrix(true , predicted)\n",
    "print(mat)\n",
    "\n",
    "df_cm = pd.DataFrame(mat, range(3), range(3))\n",
    "\n",
    "sns.heatmap(df_cm, annot=True)\n",
    "plt.show()\n",
    "\n",
    "sklearn.metrics.classification_report(true,predicted,target_names=['favorable','neutral','unfavorable'])\n",
    "sklearn.metrics.accuracy_score(true,predicted)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Live Demo and Model Testing\n",
    "This function allows for the model to be evaluated with manually prompted data, a user interface for evaluating the model with real time and human generated queries."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_result(statement):\n",
    "    result = model.predict([statement])\n",
    "    pos = np.where(result[1][0] == np.amax(result[1][0]))\n",
    "    pos = int(pos[0])\n",
    "    sentiment_dict = {0:'positive',1:'negative',2:'neutral'}\n",
    "    print(sentiment_dict[pos])\n",
    "    return\n",
    "\n",
    "sentiment = get_result(input(\"Input a phrase for Validation: \"))\n",
    "print(\"The input data was classified as:\", sentiment)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}